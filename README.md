# ğŸ§ª NeurIPS 2025: Open Polymer Prediction Challenge

**ğŸ¥ˆ Silver Medal | Top 50 (Rank #50 / Score: 0.087)**  
**Competition:** [NeurIPS 2025 â€“ Open Polymer Prediction](https://www.kaggle.com/competitions/neurips-2025-open-polymer-prediction)

---

## ğŸ§¬ Overview

This project was developed as part of the **NeurIPS 2025: Open Polymer Prediction** competition on Kaggle.  
The goal of the challenge was to **predict key polymer properties directly from their chemical structures**, enabling better design and discovery of novel materials.

---

## ğŸ† Results

- ğŸ¥ˆ **Silver Medalist**
- ğŸŒ **Top 50 globally (Rank: 50)**
- ğŸ“ˆ **Final Score:** 0.087  

This was my **first Kaggle Silver Medal**, marking a milestone in my data science journey.

---

## âš™ï¸ Approach

### ğŸ”¹ Feature Engineering (RDKit)
Utilized the **RDKit** library to extract and compute molecular representations:
- **Physicochemical Descriptors** â€“ e.g., molecular weight, LogP, TPSA  
- **Molecular Fingerprints** â€“ *Morgan* (ECFP), *MACCS*, structural patterns  
- **Structural Features** â€“ counts of atoms, bonds, functional groups  

### ğŸ”¹ Modeling
Explored and tuned multiple algorithms:
- **CatBoost**
- **LightGBM**
- **Random Forest**
- **Stacked Ensembles** (combining tree-based models for improved generalization)

### ğŸ”¹ Techniques
Key steps that improved performance:
- Data cleaning & preprocessing  
- Feature scaling & clipping  
- Cross-validation strategies  
- Model ensembling & weighted blending  

---

## ğŸ“Š Insights

Working on this problem deepened my understanding of:
- How **different molecular representations** affect predictive performance  
- The **trade-offs** between single-model simplicity and ensemble robustness  
- Practical aspects of **feature importance** and **model interpretability** in chemistry-related ML tasks  

---

## ğŸ§  Learnings & Reflections

This competition provided a hands-on opportunity to explore the intersection of **machine learning** and **computational chemistry**.  
It reinforced how thoughtful **feature engineering** and **ensemble modeling** can significantly boost results in structured scientific data problems.

Iâ€™m grateful to the **Kaggle community** and **NeurIPS organizers** for enabling such an inspiring and educational experience and I look forward to taking on more advanced challenges in the future.

---

## ğŸ“š Tech Stack

| Category | Tools / Libraries |
|-----------|------------------|
| **Languages** | Python |
| **Libraries** | RDKit, Pandas, NumPy, Scikit-learn, CatBoost, LightGBM |
| **Visualization** | Matplotlib, Seaborn |
| **Environment** | Kaggle Notebooks, JupyterLab |

---

## ğŸ¤ Acknowledgements

A huge thanks to:
- **Kaggle community** for shared insights and discussions  
- **NeurIPS 2025 organizers** for curating an engaging, real-world problem  

---

**Author:** [AK](https://www.kaggle.com/evilak09)  
**Competition:** [NeurIPS 2025 â€“ Open Polymer Prediction](https://www.kaggle.com/competitions/neurips-open-polymer-prediction-2025)
